var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = Polyester","category":"page"},{"location":"#Polyester","page":"Home","title":"Polyester","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [Polyester]","category":"page"},{"location":"#Polyester.UnsignedIteratorEarlyStop","page":"Home","title":"Polyester.UnsignedIteratorEarlyStop","text":"UnsignedIteratorEarlyStop(thread_mask[, num_threads = count_ones(thread_mask)])\n\nIterator, returning (i,t) = Tuple{UInt32,UInt32}, where i iterates from 1,2,...,num_threads, and t gives the threadids to call ThreadingUtilities.taskpointer with.\n\nUnfortunately, codegen is suboptimal when used in the ergonomic for (i,tid) ∈ thread_iterator fashion. If you want to microoptimize, You'd get better performance from a pattern like:\n\nfunction sumk(u,l = count_ones(u) % UInt32)\n    uu = ServiceSolicitation.UnsignedIteratorEarlyStop(u,l)\n    s = zero(UInt32); state = ServiceSolicitation.initial_state(uu)\n    while true\n        iter = iterate(uu, state)\n        iter === nothing && break\n        (i,t),state = iter\n        s += t\n    end\n    s\nend\n\nThis iterator will iterate at least once; it's important to check and exit early with a single threaded version.\n\n\n\n\n\n","category":"type"},{"location":"#Polyester.@batch-Tuple{Any}","page":"Home","title":"Polyester.@batch","text":"@batch for i in Iter; ...; end\n\nEvaluate the loop on multiple threads.\n\n@batch minbatch=N for i in Iter; ...; end\n\nEvaluate at least N iterations per thread. Will use at most length(Iter) ÷ N threads.\n\n@batch per=core for i in Iter; ...; end\n@batch per=thread for i in Iter; ...; end\n\nUse at most 1 thread per physical core, or 1 thread per CPU thread, respectively. One thread per core will mean less threads competing for the cache, while (for example) if there are two hardware threads per physical core, then using each thread means that there are two independent instruction streams feeding the CPU's execution units. When one of these streams isn't enough to make the most of out of order execution, this could increase total throughput.\n\nWhich performs better will depend on the workload, so if you're not sure it may be worth benchmarking both.\n\nLoopVectorization.jl currently only uses up to 1 thread per physical core. Because there is some overhead to switching the number of threads used, per=core is @batch's default, so that Polyester.@batch and LoopVectorization.@tturbo work well together by default.\n\nYou can pass both per=(core/thread) and minbatch=N options at the same time, e.g.\n\n@batch per=thread minbatch=2000 for i in Iter; ...; end\n@batch minbatch=5000 per=core   for i in Iter; ...; end\n\n\n\n\n\n","category":"macro"}]
}
